{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from Bio.AlignIO import read\n",
    "from IPython.display import clear_output\n",
    "from Bio.Seq import _translate_str\n",
    "from Bio.Data import CodonTable\n",
    "table = CodonTable.ambiguous_dna_by_id[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nTail': [21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142]},\n",
       " {'cTail': []},\n",
       " {'NSL': []},\n",
       " {'Apical': []},\n",
       " {'Equitorial': [150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196,\n",
       "   197,\n",
       "   198,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   232,\n",
       "   233,\n",
       "   234,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257,\n",
       "   258,\n",
       "   259,\n",
       "   260,\n",
       "   261,\n",
       "   262,\n",
       "   263,\n",
       "   264,\n",
       "   265,\n",
       "   266,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   272,\n",
       "   273,\n",
       "   274,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   278,\n",
       "   279,\n",
       "   280,\n",
       "   281,\n",
       "   282,\n",
       "   283,\n",
       "   284,\n",
       "   285,\n",
       "   286,\n",
       "   287,\n",
       "   288,\n",
       "   289,\n",
       "   290,\n",
       "   291,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   295,\n",
       "   296,\n",
       "   297,\n",
       "   298,\n",
       "   299,\n",
       "   300,\n",
       "   301,\n",
       "   302,\n",
       "   303,\n",
       "   304,\n",
       "   305,\n",
       "   306,\n",
       "   307,\n",
       "   308,\n",
       "   309,\n",
       "   310,\n",
       "   311,\n",
       "   312,\n",
       "   313,\n",
       "   314,\n",
       "   315,\n",
       "   316,\n",
       "   317,\n",
       "   318,\n",
       "   319,\n",
       "   320,\n",
       "   321,\n",
       "   322,\n",
       "   323,\n",
       "   324,\n",
       "   325,\n",
       "   326,\n",
       "   327,\n",
       "   328,\n",
       "   329,\n",
       "   330,\n",
       "   331,\n",
       "   332,\n",
       "   333,\n",
       "   334,\n",
       "   335,\n",
       "   336,\n",
       "   371,\n",
       "   372,\n",
       "   373,\n",
       "   374,\n",
       "   375,\n",
       "   376,\n",
       "   377,\n",
       "   378,\n",
       "   379,\n",
       "   380,\n",
       "   381,\n",
       "   382,\n",
       "   383,\n",
       "   384,\n",
       "   385,\n",
       "   386,\n",
       "   387,\n",
       "   388,\n",
       "   389,\n",
       "   390,\n",
       "   391,\n",
       "   392,\n",
       "   393,\n",
       "   394,\n",
       "   395,\n",
       "   396,\n",
       "   397,\n",
       "   398,\n",
       "   399,\n",
       "   400,\n",
       "   401,\n",
       "   402,\n",
       "   403,\n",
       "   404,\n",
       "   405,\n",
       "   406,\n",
       "   407,\n",
       "   408,\n",
       "   409,\n",
       "   410,\n",
       "   411,\n",
       "   412,\n",
       "   413,\n",
       "   414,\n",
       "   415,\n",
       "   416,\n",
       "   417,\n",
       "   418,\n",
       "   419,\n",
       "   420,\n",
       "   421,\n",
       "   422,\n",
       "   423,\n",
       "   424,\n",
       "   425,\n",
       "   426,\n",
       "   427,\n",
       "   428,\n",
       "   429,\n",
       "   430,\n",
       "   431,\n",
       "   432,\n",
       "   433,\n",
       "   434,\n",
       "   435,\n",
       "   436,\n",
       "   437,\n",
       "   438,\n",
       "   439,\n",
       "   440,\n",
       "   441,\n",
       "   442,\n",
       "   443,\n",
       "   444,\n",
       "   445,\n",
       "   446,\n",
       "   447]},\n",
       " {'Intermediate': []}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa=read(\"/Users/ptdolan/Downloads/Master_Alignment/eukaryotic_masterinput_100seq_18orig.aln\", \"fasta\")\n",
    "coverage=1-np.array([sum(i) for i in np.transpose(np.array([[i==\"-\" for i in fa[j].seq] for j in range(len(fa))]))])/len(fa)\n",
    "\n",
    "AlignedMin=0.5\n",
    "columns=coverage>AlignedMin\n",
    "covered=[i for i in range(len(columns)) if columns[i]]\n",
    "\n",
    "regions=dict()\n",
    "\n",
    "#N-tails\n",
    "regions[\"nTail\"]=list(range((1*3)-3,((50*3)-3)))\n",
    "\n",
    "#C-tails\n",
    "regions[\"cTail\"]=list(range((627*3)-3,((655*3)-3)))\n",
    "\n",
    "#Nucleotide Sensing Loop\n",
    "regions[\"NSL\"]=list(range((199*3),209*3))\n",
    "\n",
    "#Apical Domain\n",
    "regions[\"Apical\"]=list(range((263*3)-3,((451*3)-3)))\n",
    "\n",
    "#Equitorial Domain\n",
    "regions[\"Equitorial\"]=list(range((51*3)-3,((177*3)-3)))+list(range((490*3)-3,((626*3)-3)))\n",
    "\n",
    "#Intermediate Domain\n",
    "regions[\"Intermediate\"]=list(range((178*3)-3,((262*3)-3)))+list(range((452*3)-3,((489*3)-3)))\n",
    "\n",
    "#Filter\n",
    "selectRegions=[{key:[i for i in regions[key] if i in covered]} for key in regions.keys()]\n",
    "selectRegions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ranger(Trees,nameDict,dim,outfile,selection):#Analyze All Trees\n",
    "    print(\"Ranger...\")\n",
    "    with open(outfile,'w') as W:\n",
    "        pass\n",
    "    n=0\n",
    "    allTreeDF=pd.DataFrame()\n",
    "    head=True\n",
    "    for i in range(len(Trees)):#for each tree\n",
    "        n+=1\n",
    "        print(\"Parsing Tree:\"+str(n)) \n",
    "        #print(Trees[i])\n",
    "        [seqtable,taxatable,pItable,disttable,gravytable,aromatable,chargetable]=extractTables(Trees[i],nameDict,dim,selection)\n",
    "        lineageDF=evaluateLineages(nameDict,seqtable,taxatable,pItable,disttable,gravytable,aromatable,chargetable,n,dim)\n",
    "        with open(outfile,\"a\") as OF:\n",
    "            lineageDF.to_csv(OF, header=head)\n",
    "        head=False\n",
    "        clear_output()\n",
    "    print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extractTables(Tree,nameDict,dim,selection):\n",
    "    print(\"Extracting Ancestral Data...\")\n",
    "    depth=0\n",
    "    width=0\n",
    "    #create sufficiently large tables !!!How to best determine maximum size\n",
    "\n",
    "    taxatable=np.full(fill_value=\"\",dtype=\"|S4\",shape=(dim,dim))#UP TO 4 PLACES (9999 TAXA)\n",
    "    pItable=np.full(fill_value=-1,dtype=\"float\",shape=(dim,dim))#UP TO 2500 RESIDUES\n",
    "    gravytable=np.full(fill_value=-1,dtype=\"float\",shape=(dim,dim))#\n",
    "    chargetable=np.full(fill_value=0,dtype=\"float\",shape=(dim,dim))#\n",
    "    aromatable=np.full(fill_value=-1,dtype=\"float\",shape=(dim,dim))#\n",
    "    seqtable=np.full(fill_value=\"\",dtype=\"|S2500\",shape=(dim,dim))#UP TO 25 RESIDUES\n",
    "    disttable=np.full(fill_value=-1,dtype=\"float\",shape=(dim,dim))#\n",
    "    \n",
    "    for limb in Tree:\n",
    "        #print(limb)\n",
    "        #Read the string and parse breakpoints\n",
    "        reading=\"\"\n",
    "        openBlock=0\n",
    "        for i in limb: #for character in string\n",
    "            if i == \"(\":\n",
    "                depth+=1\n",
    "                #print(depth)\n",
    "                \n",
    "            elif ((i ==\"[\")|(openBlock>0)): #capture annot blocks which contain commas, bypass comma filter (below) in blocks. \n",
    "                reading=\"\".join([reading,i])\n",
    "                #print(reading)\n",
    "                if i ==\"[\":\n",
    "                    openBlock+=1               \n",
    "                if i ==\"]\":\n",
    "                    openBlock-=1\n",
    "                    #print(reading)\n",
    "                    \n",
    "            elif i == \",\": #new taxa\n",
    "                #print(\"new taxa\")\n",
    "                #print(reading)\n",
    "                seq,taxa,brDist=parseReading(reading,selection)#end of string\n",
    "                #print(seq)\n",
    "                pI,gravy,aroma,charge=aaAnalyze(seq)#calculate peptide characteristics \n",
    "                #print(pI)\n",
    "                pItable[depth][width]=pI\n",
    "                seqtable[depth][width]=seq\n",
    "                taxatable[depth][width]=taxa\n",
    "                gravytable[depth][width]=gravy\n",
    "                aromatable[depth][width]=aroma\n",
    "                chargetable[depth][width]=charge\n",
    "                disttable[depth][width]=brDist\n",
    "                \n",
    "                reading=\"\"\n",
    "                width+=1\n",
    "                \n",
    "            else: #grow string \n",
    "                reading=\"\".join([reading,i])\n",
    "                #print(reading)\n",
    "        \n",
    "        seq,taxa,brDist=parseReading(reading,selection)\n",
    "        pI,gravy,aroma,charge=aaAnalyze(seq)\n",
    "        pItable[depth][width]=pI\n",
    "        seqtable[depth][width]=seq\n",
    "        taxatable[depth][width]=taxa\n",
    "        gravytable[depth][width]=gravy\n",
    "        aromatable[depth][width]=aroma\n",
    "        chargetable[depth][width]=charge\n",
    "        disttable[depth][width]=brDist\n",
    "        reading=\"\"\n",
    "        depth-=1    \n",
    "        \n",
    "    return([seqtable,taxatable,pItable,disttable,gravytable,aromatable,chargetable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseReading(reading,selection):\n",
    "    #print(\"parseReading...\")\n",
    "    spBlock=re.split('\\]:|\\[&|\\]',reading)\n",
    "    #print(spBlock)\n",
    "    seqBlock=spBlock[1]\n",
    "    #seq=_translate_str(mergeCodons(seqBlock,selection),table=table,cds=False)\n",
    "    seq=mergeCodons(seqBlock,selection)\n",
    "    taxa=spBlock[0]\n",
    "    if len(spBlock)>3:\n",
    "        branchData=float(spBlock[4])\n",
    "    else:\n",
    "        branchData=0.00\n",
    "    return(seq,taxa,branchData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeCodons(seqBlock,selection):\n",
    "    #print(seqBlock)\n",
    "    chunks=seqBlock.split(\",\")#preparsed chunks\n",
    "    strings=[chunk.split(\"=\")[1].replace(\"\\\"\",\"\") for chunk in chunks]#pull out sequence element\n",
    "    reorderedSeq=[string[i] for i in range(len(strings[0])) for string in strings]#join all the sequences in order\n",
    "    mergeSeq=\"\".join([reorderedSeq[i] for i in selection])\n",
    "    print(mergeSeq)\n",
    "    return(mergeSeq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseNames(taxNames):#specific to the data set? do specific parts in R?\n",
    "    names=[i.strip(\",\").split(\" \") for i in taxNames]\n",
    "    names=[name for name in names if len(name)==2]\n",
    "    return(dict(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaAnalyze(peptide):\n",
    "    print(peptide)\n",
    "    peptideObj=ProteinAnalysis(peptide.replace('\\\"','').replace(\"\\];\",\"\").replace(\"*\",\"\"))\n",
    "    pI=peptideObj.isoelectric_point()\n",
    "    gravy=peptideObj.gravy()\n",
    "    aroma=peptideObj.aromaticity()\n",
    "    charge=peptideObj.charge_at_pH(pH=7)\n",
    "    return(pI,gravy,aroma,charge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traceBack(taxName,taxatable,pItable,seqtable,disttable,gravytable,aromatable,chargetable,i,j,n,dim):\n",
    "    output=pd.DataFrame(index=[n],data={'i': [i], 'j': [j], 'taxLineage':taxName,'brDist':disttable[i][j],'gravy':gravytable[i][j],'aroma':aromatable[i][j],'charge':chargetable[i][j],'pI':pItable[i][j],'seq':seqtable[i][j]})\n",
    "    k=i\n",
    "    l=j\n",
    "    while k > 0 and l < dim:\n",
    "        k-=1\n",
    "        #print(k)\n",
    "        if (seqtable[k][l]!=b'') & (taxatable[k][l]==b''):\n",
    "            #print(str(k)+\",\"+str(l))\n",
    "            #print(seqtable[k][l])\n",
    "            output=output.append(pd.DataFrame(index=[n],data={'i': [k], 'j': [l], 'taxLineage':taxName,'brDist':disttable[k][l],'gravy':gravytable[k][l],'aroma':aromatable[k][l],'charge':chargetable[k][l],'pI':pItable[k][l],'seq':seqtable[k][l]}))\n",
    "        elif(seqtable[k][l]==b''):\n",
    "            k+=1 #stay in same depth\n",
    "            l+=1\n",
    "        else: \n",
    "            print(\"Tree Issue... Check File.\")\n",
    "    output=output.sort_values(by='i',ascending=True)\n",
    "    output['brDist']=output['brDist'].cumsum()\n",
    "    return(output)\n",
    "    \n",
    "def evaluateLineages(taxNames,seqtable,taxatable,pItable,disttable,gravytable,aromatable,chargetable,n,dim):\n",
    "    print(\"Tracing lineages...\")\n",
    "    traceDF=pd.DataFrame()\n",
    "    for i in range(len(seqtable)-1,0,-1):#scales at 0 N^2\n",
    "        for j in range(len(seqtable[i])):\n",
    "            if seqtable[i][j] != b'':\n",
    "                if taxatable[i][j]:#walkBACK\n",
    "                    taxName=taxatable[i][j]\n",
    "                    #print(str(i)+str(j))\n",
    "                    #print(taxName)\n",
    "                    traceTable=traceBack(taxName,taxatable,pItable,seqtable,disttable,gravytable,aromatable,chargetable,i,j,n,dim)\n",
    "                    traceDF=traceDF.append(traceTable)\n",
    "    traceDF.seq=[i.decode('UTF8') for i in traceDF.seq]\n",
    "    traceDF.taxLineage=[taxNames[i.decode('UTF8')] for i in traceDF.taxLineage]\n",
    "    return(traceDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "TREEFILE=\"/Users/ptdolan/Desktop/BEAST_OUTPUTS_0820/eukaryotic_split_100seq_18orig.fa_basicAA.nxs.trees\",\n",
    "for reg in selectRegions:\n",
    "    for key in reg.keys():\n",
    "        selection=reg[key]\n",
    "        BurnProp=0.9\n",
    "        with open(TREEFILE, 'r') as IF:\n",
    "            R=[line.strip() for line in IF.readlines() if line.startswith(\"tree\")]\n",
    "        with open(TREEFILE,'r') as IF:\n",
    "            taxNames=[line.strip() for line in IF.readlines() if not line.startswith(\"tree\")]\n",
    "\n",
    "        newick=[i.split(\" = [&R] \") for i in R]\n",
    "        treeStats=[i[0] for i in newick]#tree likelihood data\n",
    "        trees=[i[1].split(\")\") for i in newick]#tree strcture and ancestral data string\n",
    "\n",
    "        print(\"Number of Trees: \" + str(len(trees)))\n",
    "        BurnIn=int(BurnProp*len(trees))\n",
    "\n",
    "        print(\"Processing \"+str(len(trees)-BurnIn)+\" trees beginning at \"+str(BurnIn))\n",
    "\n",
    "        nameDict=parseNames(taxNames)\n",
    "        #print(nameDict.values())\n",
    "        dim=2*(len(taxNames)-2)\n",
    "        Forest=Ranger(trees[BurnIn::],nameDict,dim,\"ASR_CCT2020_100M_\"+key+\".csv\",selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
